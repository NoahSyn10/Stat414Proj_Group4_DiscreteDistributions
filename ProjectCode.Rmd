---
title: "STAT414"
author: "Aminah W, Noah S, Gabriella L, Nathanael N"
date: "2022-12-05"
output: pdf_document
---

# Binomial Distribution

The built-in function dbinom(x, size, probability) evaluates the probability density function (PDF) for a binomial distribution. For example, below the dbinom() is used to determine the probability of 3 successes in 5 trials (x = 3) given that the probability of a success is 0.2.

```{r eval==TRUE}
#binomial pdf
dbinom(3,5,0.2)
```

We can verify that dbinom() is accurate using the formula for the PDF of a binomial distribution:

```{r eval}
choose(5,3)*(0.2)^3*(0.8)^2
```

The built-in function pbinom(x, size, probability) evaluates the cumulative density function (CDF) for a binomial distribution. For example, below the pbinom() is used to determine the cumulative probability of 3 successes in 5 trials (x = 3) given that the probability of a success is 0.2.

```{r eval}
#binomial cdf
pbinom(3,5,0.2)
```

We can verify that pbinom() is accurate using the formula for the CDF of a binomial distribution:

```{r eval}
choose(5,0)*(0.2)^0*(0.8)^(5) + choose(5,1)*(0.2)^1*(0.8)^(4) + choose(5,2)*(0.2)^2*(0.8)^(3) + choose(5,3)*(0.2)^3*(0.8)^(2)
```

We can also plot the PDF and CDF.

```{r eval}
library(dplyr)
library(ggplot2)


x= 0:10
plot(pbinom(x,5,0.2), type = "s", main = "CDF Bin ~ (5, 0.2) for x = 0 to x = 10")



# expectation
x = c(0, 1, 2, 3)
prob = dbinom(x,5,0.2)*x
E = sum(prob)

# variance
prob2 =dbinom(x,5,0.2)*x^2
V = sum(prob2)-(sum(prob)^2)

x= 0:10
plot(dbinom(x,5,0.2), type = "h", main = "PDF Bin ~ (5, 0.2) for x = 0 to x = 10")
abline(v = E, col = "red")

text(2, 0.35, "Mean = 0.9728", col = "red")
text(2.2, 0.32, "Variance = 0.7433", col = "blue")


```

# Hypergeometric Distribution

The built-in function dhyper(x,m,n,k) evaluates the probability density function (PDF) for a hypergeometric distribution. For example, below the dhyper() is used to determine the probability ...(revise later)

```{r eval = TRUE}
# hypergeometric pdf
dhyper(2,4,6,5)
(choose(4,2)*choose(6,3))/choose(10,5)

# hypergeometric cdf
phyper(2,4,6,5) 
(choose(4,0)*choose(6,5))/choose(10,5) +(choose(4,1)*choose(6,4))/choose(10,5)+
(choose(4,2)*choose(6,3))/choose(10,5)

```

# Poisson Distribrution

```{r eval=TRUE}
#Poisson pdf
dpois(0,5/2)
(exp(-5/2)*(5/2)^0)/factorial(0)

#Poisson cdf
ppois(1,5/2)
(exp(-5/2)*(5/2)^0)/factorial(0) + (exp(-5/2)*(5/2)^1)/factorial(1)
```

# Sample Size

Sample size plays a big role in the shape of data.

```{r eval}

Samples = rbinom(100, 5, 0.2)
hist(Samples, breaks = 0:5.5, probability = TRUE, main = "Random Samples from Bin(5, 0.2) for x = 100")
lines(x, dbinom(x,5,0.2), col = "darkgreen", lwd = 2)
text(2.4, 0.3, "PMF for Bin(5,0.2)", col = "darkgreen")

```

When we generate 100 samples of the Binomial Distribution and graph a histogram of the results, it is notable that the histogram tends to have a bell curve.

```{r eval}
samples = rbinom(100, 30, 0.25)
hist(samples)

```

# Relationship Between Distributions

While each Discrete Distribution has a unique meaning and application, they still have similar foundations, and thus hold observable relationships between each other. For example, we know that the Hypergeometric Distribution applies to a random variable X in a situation where there is a population size of N with m correct choices, and a sample size n chosen *without replacement*. Similarly, the Binomial Distribution applies to random variable X with a sample size of n and a *constant probability* p. Imagine that the Hypergeometric random variable's sample size was modified to be chosen with replacement. It is clear that the random variable would then have a Binomial Distribution with sample size n and constant probability p=m/N. Now imagine that the Hypergeometric random variable had a population size so large that taking a sample did not significantly change the ratio m/N. Then the PMF would be very similar to that of a Binomial Distribution with sample size n and probability m/N, as the probability would be *near constant*. In fact, as the population size of a Hypergeometric Distribution approaches infinity, its PMF approaches the PMF of a Binomial Distribution with p=m/N. Thanks to this characteristic of the Hypergeometric Distribution, for certain parameters we can actually use the PMF of the Binomial Distribution to approximate that of a Hypergeometric random variable.

This can be illustrated by plotting the PMF of a Hypergeometric Distribution with a population size N and a sample size n much less than N against the PMF of a Binomial distribution with sample size n and probability p=m/N, m being the number of correct choices in population N. Lets consider a Hypergeometric Distribution with population N=1000, with m=100 correct choices and a sample size of n=50. We could approximate the PMF of that random variable with a Binomial Distribution with sample size n=50 and probability p=100/1000=0.1

```{r eval}

# Plot the PMF of a Hyergeometric Random Variable with the PMF of a Binomial Random Variable that could be used to approximate it

x <- 0:20

N=1000  # Population size 1000
m=100   # 100 correct choices
n=50    # Sample size 50

# Probability of x successes in 50 trials with 1000 choices, 100 of them correct.
hyperPMF <- dhyper(x, m, N-m, n)

# Probability of x successes in 50 trials with prob 0.1
binomPMF <- dbinom(x, n, m/N)

# Plot both functions
plot(hyperPMF, xlim = c(0, 20), ylim = c(0, 0.25), col='black', type='o')
points(binomPMF, xlim = c(0, 20), ylim = c(0, 0.25), col='red', type='b')
legend(15, 0.25, legend=c("Hyper Geometric", "Binomial"), 
       col=c("black", "red"), lty=1:2, cex=.75)
```

Similar to how the Hypergeometric PMF can be approximated using the Binomial PMF, a the Binomial PMF can be approximated using the Poisson PMF. We know that a Binomial Distribution applies to a random variable X with sample size n and probability p, and its PMF calculates the probability that X=x successes will occur in the sample size. On the other hand, the Poisson Distribution applies to a random variable X with a success frequency λ over an interval, and its PMF calculates the probability that X=x successes will occur within that interval. If we reimagine the Binomial PMF with the sample size n as an interval [0, n] and frequency λ=n\*p, we can see how the Binomial PMF could be approximated using the Poisson PMF. In fact the Binomial PMF approaches the Poisson PMF as n grows very large and p becomes very small such that λ stays the same.

To illustrate this relationship lets consider a Binomial Distribution with sample size N=100 and probability p=0.05. This could be approximated using a Poisson Distribution if we imagine a range [0, 100] where the frequency of success is λ=100\*0.05=5.

```{r eval}

# Plot the PMF of a Binomial Random Variable with the PMF of a Poisson Random Variable that could be used to approximate it

x <- 0:20

n=100   # Sample size 100
p=0.05  # Probability 0.05

# Probability of x successes in 50 trials with prob 0.1
binomPMF <- dbinom(x, n, p)

# Probability of x occurances with an occurance rate of 10
poisPMF <- dpois(x, n*p)

# Plot both functions
plot(binomPMF, xlim = c(0, 20), ylim = c(0, 0.25), col='black', type='o')
points(poisPMF, xlim = c(0, 20), ylim = c(0, 0.25), col='red', type='b')
legend(15, 0.25, legend=c("Binomial", "Poisson"), 
       col=c("black", "red"), lty=1:2, cex=.75)
```

Knowing that the Hypergeometric PMF can be approximated with the Binomial PMF and the Binomial PMF can be approximated with the Poisson PMF, we know that under some conditions the Hypergeometric PMF must be able to be approximated by the Poisson PMF. To find those conditions, consider that the Hypergeometric PMF approaches the Binomial PMF when the population size grows very large and the sample size stays significantly smaller, and the Binomial PMF approaches the Poisson PMF when the sample size grows very large and the probability becomes very small. From these conditions we can derive that the Hypergeometric PMF would best approach the Poisson PMF when the both the population and sample size grow very large while the sample size stays a fraction of the population size, and the number of correct options m stays small such that the probability p=m/N will become very small.

Lets consider a Hypergeometric Distribution with a Population N=10,000 with m=500 correct choices, and a sample size of n=100. This will be approximated using a Binomial Distribution with sample size n=100 and probability p=10,000/500=0.05. Finally the Binomial Distribution will be approximated with a Poisson Distribution with frequency λ=100\*0.05=5.

```{r eval}

# Plot the PMF of a Binomial Random Variable with the PMF of a Poisson Random Variable that could be used to approximate it

x <- 0:20

N=10000  # Population size 10000
m=500    # 500 correct choices
n=100    # Sample size 100

# Probability of x successes in 50 trials with 1000 choices, 100 of them correct.
hyperPMF <- dhyper(x, m, N-m, n)

# Probability of x successes in 50 trials with prob 0.1
binomPMF <- dbinom(x, n, m/N)

# Probability of x occurances with an occurance rate of 10
poisPMF <- dpois(x, n*(m/N))

# Plot all three functions
plot(hyperPMF, xlim = c(0, 20), ylim = c(0, 0.25), col='black', type='o')
points(binomPMF, xlim = c(0, 20), ylim = c(0, 0.25), col='red', type='b')
points(poisPMF, xlim = c(0, 20), ylim = c(0, 0.25), col='blue', type='b')
legend(15, 0.25, legend=c("Hypergeometric", "Binomial", "Poisson"), 
       col=c("black", "red", "blue"), lty=1:3, cex=.75)


```

# Central Limit Theorem

```{r eval}

# Generate 100 samples of a Binomial Distribution and find the mean of the results. Repeat 50 times, and graph the histogram of the 50 means.

means = c() # Init vector to store means
for(i in 1:50) {
  samples = rbinom(100, 30, 0.25)
  means = append(means, mean(samples))
}
hist(means)
```
